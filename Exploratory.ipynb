{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
      "       'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
      "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n",
      "       'ORGANIZATION_TYPE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 5</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 6</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 7</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 1</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 2</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 3</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_University</th>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-16941</td>\n",
       "      <td>-1588</td>\n",
       "      <td>-4970</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0       1             0          202500.0    406597.5      24700.5   \n",
       "1       0             0          270000.0   1293502.5      35698.5   \n",
       "2       0             0           67500.0    135000.0       6750.0   \n",
       "3       0             0          121500.0    513000.0      21865.5   \n",
       "4       0             0           99000.0    490495.5      27517.5   \n",
       "\n",
       "   AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0         351000.0                    0.018801       -9461           -637   \n",
       "1        1129500.0                    0.003541      -16765          -1188   \n",
       "2         135000.0                    0.010032      -19046           -225   \n",
       "3         513000.0                    0.028663      -19932          -3038   \n",
       "4         454500.0                    0.035792      -16941          -1588   \n",
       "\n",
       "   DAYS_REGISTRATION  ...  ORGANIZATION_TYPE_Trade: type 4  \\\n",
       "0              -3648  ...                                0   \n",
       "1              -1186  ...                                0   \n",
       "2              -4260  ...                                0   \n",
       "3              -4311  ...                                0   \n",
       "4              -4970  ...                                0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Trade: type 5  ORGANIZATION_TYPE_Trade: type 6  \\\n",
       "0                                0                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  \\\n",
       "0                                0                                    0   \n",
       "1                                0                                    0   \n",
       "2                                0                                    0   \n",
       "3                                0                                    0   \n",
       "4                                0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
       "0                                    0                             0   \n",
       "1                                    0                             0   \n",
       "2                                    0                             0   \n",
       "3                                    0                             0   \n",
       "4                                    0                             0   \n",
       "\n",
       "   ORGANIZATION_TYPE_XNA  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('application_train_clean.csv')\n",
    "df = df.drop(['Unnamed: 0','SK_ID_CURR'],axis=1)\n",
    "print(df.columns[df.dtypes == object])\n",
    "df = pd.get_dummies(df, columns = df.select_dtypes(include=['object']).columns, drop_first=True, dtype=int)\n",
    "df.to_csv('cleaned_train.csv', index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('TARGET',axis=1), df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split\n",
    "def stratified_split(data, test_size=0.1, validation_size = 0.1):\n",
    "\n",
    "    class_1 = data[data['TARGET'] == 1]\n",
    "    class_0 = data[data['TARGET'] == 0]\n",
    "\n",
    "    test_count_1 = int(len(class_1) * test_size)\n",
    "    validation_count_1 = int(len(class_1) * validation_size)\n",
    "    test_count_0 = int(len(class_0) * test_size)\n",
    "    validation_count_0 = int(len(class_0) * validation_size)\n",
    "\n",
    "    class_1 = class_1.sample(frac=1)\n",
    "    class_0 = class_0.sample(frac=1)\n",
    "\n",
    "    # Split each class into test, validation, and train sets\n",
    "    test_data = pd.concat([class_1.iloc[:test_count_1], class_0.iloc[:test_count_0]])\n",
    "    validation_data = pd.concat([\n",
    "        class_1.iloc[test_count_1:test_count_1 + validation_count_1],\n",
    "        class_0.iloc[test_count_0:test_count_0 + validation_count_0]\n",
    "    ])\n",
    "    train_data = pd.concat([\n",
    "        class_1.iloc[test_count_1 + validation_count_1:],\n",
    "        class_0.iloc[test_count_0 + validation_count_0:]\n",
    "    ])\n",
    "\n",
    "    # Split features and target for each set\n",
    "    X_train = train_data.drop('TARGET',axis=1)\n",
    "    X_test = test_data.drop('TARGET',axis=1)\n",
    "    X_val = validation_data.drop('TARGET',axis=1)\n",
    "    y_train = train_data['TARGET']\n",
    "    y_test = test_data['TARGET']\n",
    "    y_val = validation_data['TARGET']\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 224243    1\n",
       "173991    1\n",
       "115205    1\n",
       "68818     1\n",
       "47700     1\n",
       "         ..\n",
       "50620     0\n",
       "100886    0\n",
       "214539    0\n",
       "91403     0\n",
       "29895     0\n",
       "Name: TARGET, Length: 26341, dtype: int64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = stratified_split(df)\n",
    "y_val.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Split\n",
    "\n",
    "def custom_split(data, valid_prop = 0.1, test_prop = 0.1, random_seed = 1738):\n",
    "\n",
    "    train_prop = 1 - valid_prop - test_prop\n",
    "\n",
    "    # define bins for age and income\n",
    "    age_bins = [0, 40, 60, np.inf]\n",
    "    age_labels = ['young', 'middle_aged', 'senior']\n",
    "    income_bins = [0, 30000, 70000, np.inf]\n",
    "    income_labels = ['low', 'medium', 'high']\n",
    "\n",
    "    # convert age to years\n",
    "    data['age'] = data['DAYS_BIRTH']/-365\n",
    "\n",
    "    # create binned variables\n",
    "    data['age_group'] = pd.cut(data['age'], bins=age_bins, labels=age_labels)\n",
    "    data['income_group'] = pd.cut(data['AMT_INCOME_TOTAL'], bins=income_bins, labels=income_labels)\n",
    "\n",
    "    # create a key for each group (combination of gender, age, and income)\n",
    "    data['group_key'] = data['CODE_GENDER_M'].astype(str) + '_' + data['age_group'].astype(str) + '_' + data['income_group'].astype(str)\n",
    "\n",
    "    # shuffle the data\n",
    "    data = data.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "    # split the data based on key\n",
    "    train_data = pd.DataFrame()\n",
    "    val_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for key, group in data.group_by('group_key'):\n",
    "        n = len(group)\n",
    "        n_train = int(n * train_prop)\n",
    "        n_val = int(n * valid_prop)\n",
    "\n",
    "        train_data = pd.concat([train_data, group[:n_train]])\n",
    "        val_data = pd.concat([val_data, group[n_train:n_train + n_val]])\n",
    "        test_data = pd.concat([test_data, group[n_train + n_val:]])\n",
    "\n",
    "    # drop all unnecesary columns\n",
    "    train_data = train_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "    val_data = val_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "    test_data = test_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "\n",
    "    X_train = train_data.drop(['TARGET'])\n",
    "    y_train = train_data['TARGET']\n",
    "\n",
    "    X_validation = val_data.drop(['TARGET'])\n",
    "    y_validation = val_data['TARGET']\n",
    "\n",
    "    X_test = test_data.drop(['TARGET'])\n",
    "    y_test = test_data['TARGET']\n",
    "\n",
    "    return X_train, y_train, X_validation, y_validation, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_train_test_split(X, y, test_size=0.2, val_size=0.2, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    n = len(X)\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    test_indices = indices[:int(n * test_size)]\n",
    "    val_indices = indices[int(n * test_size):int(n * (test_size + val_size))]\n",
    "    train_indices = indices[int(n * (test_size + val_size)):]\n",
    "\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    X_val, y_val = X[val_indices], y[val_indices]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    return float(TP / (TP + FN)) if (TP + FN) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "    return float(TP / (TP + FP)) if (TP + FP) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def compute_accuracy(truth, predicted):\n",
    "    return np.mean(truth == predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "def calculate_f1(y_true, y_pred):\n",
    "    TP = FP = TN = FN = 0\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true == 1 and pred == 1:\n",
    "            TP += 1\n",
    "        elif true == 0 and pred == 1:\n",
    "            FP += 1\n",
    "        elif true == 0 and pred == 0:\n",
    "            TN += 1\n",
    "        elif true == 1 and pred == 0:\n",
    "            FN += 1  ,\n",
    "\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F2 Score\n",
    "def calculate_f2(y_true, y_pred, b=2):\n",
    "    r = recall(y_true, y_pred)\n",
    "    p = precision(y_true, y_pred)\n",
    "\n",
    "    if r + p == 0:\n",
    "        return 0\n",
    "\n",
    "    f2 = (1 + b**2) * (r * p) / (b**2 * r + p)\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roc_auc(y_true, y_prob):\n",
    "  sorted_indices = np.argsort(y_prob)\n",
    "  true_sort = y_true[sorted_indices]\n",
    "  prob_sort = y_prob[sorted_indices]\n",
    "\n",
    "  TP = np.cumsum(true_sort)\n",
    "  FP = np.cumsum(1 - true_sort)\n",
    "\n",
    "  TPR = TP / TP[-1]\n",
    "  FPR = FP / FP[-1]\n",
    "\n",
    "  # rocauc\n",
    "  rocauc_score = np.trapz(FPR, TPR)\n",
    "\n",
    "  return rocauc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -7.61617123548896e-08 \n",
      " weights: [-9.20745121e-08 -7.82268465e-07  3.09376823e-06  3.83392256e-06\n",
      " -3.85531612e-06 -2.97772617e-09  1.11785036e-04  1.20372071e-06\n",
      "  2.37650110e-05  1.14889235e-04 -7.61617124e-08 -7.51256996e-08\n",
      "  1.91869578e-08 -7.53717094e-08 -3.95068036e-08 -1.52292429e-08\n",
      " -2.28318903e-07 -4.96404524e-08 -4.45214285e-08 -1.30848943e-06\n",
      " -1.76998237e-09 -2.35790368e-09 -2.50407522e-09  1.39153318e-08\n",
      "  2.27292003e-08  1.54017655e-08 -1.53657166e-07 -1.63871511e-08\n",
      "  4.72020715e-08 -1.55511883e-08  3.72698940e-08  1.40631199e-04\n",
      "  0.00000000e+00  2.11496486e-08 -1.03258035e-10 -1.05356774e-09\n",
      "  2.15784443e-09 -4.11107380e-11 -2.49338378e-08 -1.71349204e-09\n",
      " -2.86347815e-11 -2.64412419e-09 -5.17452937e-12 -3.87559684e-09\n",
      " -3.43942271e-09 -1.08448408e-09 -7.12148851e-09 -4.53765732e-10\n",
      " -6.63137818e-09 -1.13831133e-10  1.28803384e-10 -1.19415074e-10\n",
      " -4.42801957e-10  9.73633975e-10 -1.54825652e-09 -4.52503807e-08\n",
      " -2.00152160e-08  1.18011109e-07 -6.23376446e-08  6.67438395e-08\n",
      " -8.35163476e-08 -4.64479397e-08 -1.56394148e-08 -2.33331820e-10\n",
      " -6.64705782e-10 -5.72910754e-10 -5.87259674e-09 -5.26204343e-08\n",
      " -5.71442376e-08 -1.15035388e-11 -1.08138152e-09 -3.74045784e-08\n",
      " -9.93491951e-11 -1.07614429e-11  1.96008075e-08 -1.37268892e-07\n",
      " -1.91697594e-08  6.09203697e-09  7.46990766e-08 -6.83324555e-08\n",
      "  4.37642109e-09 -2.35540808e-08  3.09862624e-09 -6.55176153e-08\n",
      "  3.14374022e-09 -3.92283001e-09  2.22156175e-09 -1.03295606e-08\n",
      " -2.01199326e-08 -1.43360116e-08 -8.66504317e-09 -9.86888221e-09\n",
      " -7.46231238e-09 -8.96273366e-09  1.30431428e-09 -9.19174112e-09\n",
      " -2.56405456e-09 -2.77833515e-09  9.21596312e-10  4.80177045e-11\n",
      "  1.01947697e-08 -6.99546220e-10 -1.20818408e-09 -6.80775481e-10\n",
      " -1.01408467e-08 -7.01717360e-10  3.04938410e-10  1.32979608e-09\n",
      " -7.30003254e-11 -4.73718078e-10 -1.14504940e-09 -1.56738869e-12\n",
      " -6.85331284e-10  2.89643840e-09  5.06518680e-11 -8.18773049e-10\n",
      " -1.34755147e-10 -4.93480863e-10 -4.11406905e-11 -4.45851072e-09\n",
      " -9.84550129e-10 -9.22513209e-09 -1.31121870e-10 -1.16741395e-08\n",
      " -6.81030382e-09 -4.90263873e-10 -8.29348463e-09 -6.94671145e-09\n",
      " -4.03376861e-10  4.85201909e-10 -2.25127379e-11  1.80880933e-09\n",
      " -1.29155113e-08  2.52322221e-09 -5.69021259e-09  1.66587992e-08\n",
      " -2.61344624e-09 -6.66229183e-10 -6.14325373e-10 -6.31267557e-09\n",
      " -1.48855380e-09 -2.55337954e-10 -9.75786811e-11 -1.54914690e-09\n",
      " -4.49778933e-10 -5.82535897e-10 -2.53326797e-09  4.45119290e-09\n",
      "  9.91070064e-10 -1.94612025e-09 -1.07152499e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "w = lr.coef_[0]\n",
    "b = lr.intercept_[0]\n",
    "print(f'intercept: {b} \\n weights: {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression W/ Penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -7.61617123548896e-08 \n",
      " weights: [-9.20745121e-08 -7.82268465e-07  3.09376823e-06  3.83392256e-06\n",
      " -3.85531612e-06 -2.97772617e-09  1.11785036e-04  1.20372071e-06\n",
      "  2.37650110e-05  1.14889235e-04 -7.61617124e-08 -7.51256996e-08\n",
      "  1.91869578e-08 -7.53717094e-08 -3.95068036e-08 -1.52292429e-08\n",
      " -2.28318903e-07 -4.96404524e-08 -4.45214285e-08 -1.30848943e-06\n",
      " -1.76998237e-09 -2.35790368e-09 -2.50407522e-09  1.39153318e-08\n",
      "  2.27292003e-08  1.54017655e-08 -1.53657166e-07 -1.63871511e-08\n",
      "  4.72020715e-08 -1.55511883e-08  3.72698940e-08  1.40631199e-04\n",
      "  0.00000000e+00  2.11496486e-08 -1.03258035e-10 -1.05356774e-09\n",
      "  2.15784443e-09 -4.11107380e-11 -2.49338378e-08 -1.71349204e-09\n",
      " -2.86347815e-11 -2.64412419e-09 -5.17452937e-12 -3.87559684e-09\n",
      " -3.43942271e-09 -1.08448408e-09 -7.12148851e-09 -4.53765732e-10\n",
      " -6.63137818e-09 -1.13831133e-10  1.28803384e-10 -1.19415074e-10\n",
      " -4.42801957e-10  9.73633975e-10 -1.54825652e-09 -4.52503807e-08\n",
      " -2.00152160e-08  1.18011109e-07 -6.23376446e-08  6.67438395e-08\n",
      " -8.35163476e-08 -4.64479397e-08 -1.56394148e-08 -2.33331820e-10\n",
      " -6.64705782e-10 -5.72910754e-10 -5.87259674e-09 -5.26204343e-08\n",
      " -5.71442376e-08 -1.15035388e-11 -1.08138152e-09 -3.74045784e-08\n",
      " -9.93491951e-11 -1.07614429e-11  1.96008075e-08 -1.37268892e-07\n",
      " -1.91697594e-08  6.09203697e-09  7.46990766e-08 -6.83324555e-08\n",
      "  4.37642109e-09 -2.35540808e-08  3.09862624e-09 -6.55176153e-08\n",
      "  3.14374022e-09 -3.92283001e-09  2.22156175e-09 -1.03295606e-08\n",
      " -2.01199326e-08 -1.43360116e-08 -8.66504317e-09 -9.86888221e-09\n",
      " -7.46231238e-09 -8.96273366e-09  1.30431428e-09 -9.19174112e-09\n",
      " -2.56405456e-09 -2.77833515e-09  9.21596312e-10  4.80177045e-11\n",
      "  1.01947697e-08 -6.99546220e-10 -1.20818408e-09 -6.80775481e-10\n",
      " -1.01408467e-08 -7.01717360e-10  3.04938410e-10  1.32979608e-09\n",
      " -7.30003254e-11 -4.73718078e-10 -1.14504940e-09 -1.56738869e-12\n",
      " -6.85331284e-10  2.89643840e-09  5.06518680e-11 -8.18773049e-10\n",
      " -1.34755147e-10 -4.93480863e-10 -4.11406905e-11 -4.45851072e-09\n",
      " -9.84550129e-10 -9.22513209e-09 -1.31121870e-10 -1.16741395e-08\n",
      " -6.81030382e-09 -4.90263873e-10 -8.29348463e-09 -6.94671145e-09\n",
      " -4.03376861e-10  4.85201909e-10 -2.25127379e-11  1.80880933e-09\n",
      " -1.29155113e-08  2.52322221e-09 -5.69021259e-09  1.66587992e-08\n",
      " -2.61344624e-09 -6.66229183e-10 -6.14325373e-10 -6.31267557e-09\n",
      " -1.48855380e-09 -2.55337954e-10 -9.75786811e-11 -1.54914690e-09\n",
      " -4.49778933e-10 -5.82535897e-10 -2.53326797e-09  4.45119290e-09\n",
      "  9.91070064e-10 -1.94612025e-09 -1.07152499e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression w penalty\n",
    "lr_penalty = LogisticRegression(penalty='l2', C=1.0)\n",
    "lr_penalty.fit(X, y)\n",
    "w = lr_penalty.coef_[0]\n",
    "b = lr_penalty.intercept_[0]\n",
    "print(f'intercept: {b} \\n weights: {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[ 5.81331135e-05 -4.79375358e-06 -1.66996527e-04]] \n",
      " constant: [-0.96448307]\n",
      "Actual decision boundary: [[  16590.94127187 -201195.79725874   -5775.46784354]]\n"
     ]
    }
   ],
   "source": [
    "# SVC Model\n",
    "#SVC\n",
    "# Define the pipeline with PCA, StandardScaler, and SVC\n",
    "clf = make_pipeline(\n",
    "    PCA(n_components=0.95),          # Retain x% of the variance or set a fixed number of components\n",
    "    StandardScaler(),\n",
    "    SVC(kernel=\"linear\", gamma=\"auto\")\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Retrieve the trained SVC model from the pipeline\n",
    "svc_model = clf.named_steps['svc']\n",
    "\n",
    "# Access the coefficients and intercept\n",
    "weights = svc_model.coef_\n",
    "intercept = svc_model.intercept_\n",
    "\n",
    "print(f'weights: {weights} \\n constant: {b}')\n",
    "print(f'Actual decision boundary: {-b/weights}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[-6.99163540e-03  1.31726591e-07  2.51570304e-06  7.90656431e-06\n",
      "  -2.97870729e-06  3.30432518e+00  3.10964090e-05  6.09622973e-05\n",
      "   1.22852234e-05  6.92994698e-05  2.55523588e-14 -1.13795177e+00\n",
      "   2.32766005e-01 -1.04844708e-01 -6.25567688e-02 -3.06116334e-02\n",
      "   1.04697501e-02 -1.36067968e-01  3.02887942e-01  2.76813800e-03\n",
      "  -2.55896995e-01  1.49182311e-01 -1.99011053e-01  3.04084734e-01\n",
      "   3.83162041e-03  3.11606065e-02 -2.58909916e+00  2.51117890e-02\n",
      "   1.66423113e-01 -2.74171808e-02  6.51061324e-02  9.02112208e-05\n",
      "  -5.85632194e-14  5.84966274e-01 -2.68696131e-01  5.20468085e-01\n",
      "   5.29385595e-01  1.62834989e-01  3.62887028e-01  3.65029890e-01\n",
      "  -1.06538072e+00 -1.13021294e-01  2.83997546e-01 -4.60871568e-01\n",
      "  -5.49975143e-01 -5.08995001e-01 -4.66557311e-01 -1.02500534e+00\n",
      "  -4.28563348e-01 -2.19961398e-01  5.62758668e-01  4.62208840e-01\n",
      "  -2.76730968e-02  1.31825353e-01 -1.53816093e-02 -3.96546600e-03\n",
      "  -1.66288010e-02  3.37600839e-02  2.41319189e-01  4.22802912e-01\n",
      "  -2.71682156e-01  3.72548838e-04 -3.27834494e-02 -2.24157469e-01\n",
      "  -5.34511656e-02  3.86173708e-02 -8.46201299e-02  2.10753113e-02\n",
      "   2.96658990e-02 -6.01450588e-02 -4.42241813e-01  5.05865107e-02\n",
      "  -1.18541995e+00 -3.00947038e-01  1.53792523e-01  4.42972954e-01\n",
      "   4.73662056e-01  8.67542799e-01  7.10562373e-01 -1.59479085e-01\n",
      "  -1.20447940e-02 -4.43692451e-02 -1.26470995e-01  1.18785132e-01\n",
      "   2.45754623e-01 -9.06002748e-02  2.47219648e-01  2.18883097e-01\n",
      "  -6.00143086e-02 -7.46093873e-02 -9.40538718e-02 -2.38605352e-02\n",
      "  -1.54403658e-02 -1.25651313e-02 -2.99350689e-01 -4.95165451e-01\n",
      "  -1.81870526e-01 -1.87049672e-01 -1.38665845e-01 -2.81532948e-01\n",
      "   2.72276546e-02 -3.60055594e-01 -3.59344741e-01 -3.96084679e-01\n",
      "  -3.02613478e-01 -3.96225270e-01 -2.18321638e-01  3.10836395e-02\n",
      "  -2.94680970e-01 -2.09649838e-01 -7.58390646e-01 -6.43667102e-01\n",
      "  -4.65268256e-01 -2.99013648e-02 -1.96743672e-01 -4.49693397e-01\n",
      "  -3.37576419e-01 -2.24354119e-01 -8.01347152e-01 -4.83766233e-01\n",
      "  -2.16050887e-01 -3.10661475e-01  1.03839471e-01 -2.64440062e-01\n",
      "  -6.00865880e-01 -1.16239708e-01 -2.48543538e-01 -5.51743043e-01\n",
      "  -1.56037193e-01  3.58076522e-01 -2.67016440e-01  4.01603486e-02\n",
      "  -3.40661402e-01 -2.47436162e-01 -5.42199221e-01 -9.88403825e-02\n",
      "  -3.44238657e-01 -1.94980529e-01 -3.96156827e-01 -4.83060007e-01\n",
      "  -5.67086747e-02 -8.77571154e-01 -5.48768344e-01 -5.94454834e-01\n",
      "  -1.74941374e-01 -6.92572781e-01 -3.38738070e-01  5.51900799e-01\n",
      "  -1.79126238e-01 -2.73529436e-01 -2.33242150e+01]] \n",
      " constant: [-0.96448307]\n"
     ]
    }
   ],
   "source": [
    "# LDA Model\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_model.fit(X,y)\n",
    "\n",
    "weights = lda_model.coef_\n",
    "b = lda_model.intercept_\n",
    "\n",
    "print(f'weights: {weights} \\n constant: {b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "358eb17b656811ff2b66f9224ea3a080cef3d2bd176ed3d725d04f8c6a569ed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
