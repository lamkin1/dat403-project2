{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
      "       'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
      "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n",
      "       'ORGANIZATION_TYPE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 5</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 6</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 7</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 1</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 2</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 3</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_University</th>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-16941</td>\n",
       "      <td>-1588</td>\n",
       "      <td>-4970</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0       1             0          202500.0    406597.5      24700.5   \n",
       "1       0             0          270000.0   1293502.5      35698.5   \n",
       "2       0             0           67500.0    135000.0       6750.0   \n",
       "3       0             0          121500.0    513000.0      21865.5   \n",
       "4       0             0           99000.0    490495.5      27517.5   \n",
       "\n",
       "   AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0         351000.0                    0.018801       -9461           -637   \n",
       "1        1129500.0                    0.003541      -16765          -1188   \n",
       "2         135000.0                    0.010032      -19046           -225   \n",
       "3         513000.0                    0.028663      -19932          -3038   \n",
       "4         454500.0                    0.035792      -16941          -1588   \n",
       "\n",
       "   DAYS_REGISTRATION  ...  ORGANIZATION_TYPE_Trade: type 4  \\\n",
       "0              -3648  ...                                0   \n",
       "1              -1186  ...                                0   \n",
       "2              -4260  ...                                0   \n",
       "3              -4311  ...                                0   \n",
       "4              -4970  ...                                0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Trade: type 5  ORGANIZATION_TYPE_Trade: type 6  \\\n",
       "0                                0                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  \\\n",
       "0                                0                                    0   \n",
       "1                                0                                    0   \n",
       "2                                0                                    0   \n",
       "3                                0                                    0   \n",
       "4                                0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
       "0                                    0                             0   \n",
       "1                                    0                             0   \n",
       "2                                    0                             0   \n",
       "3                                    0                             0   \n",
       "4                                    0                             0   \n",
       "\n",
       "   ORGANIZATION_TYPE_XNA  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('application_train_clean.csv')\n",
    "df = df.drop(['Unnamed: 0','SK_ID_CURR'],axis=1)\n",
    "print(df.columns[df.dtypes == object])\n",
    "df = pd.get_dummies(df, columns = df.select_dtypes(include=['object']).columns, drop_first=True, dtype=int)\n",
    "df.to_csv('cleaned_train.csv', index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('TARGET',axis=1), df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split\n",
    "def stratified_split(data, test_size=0.1, validation_size = 0.1):\n",
    "\n",
    "    class_1 = data[data['TARGET'] == 1]\n",
    "    class_0 = data[data['TARGET'] == 0]\n",
    "\n",
    "    test_count_1 = int(len(class_1) * test_size)\n",
    "    validation_count_1 = int(len(class_1) * validation_size)\n",
    "    test_count_0 = int(len(class_0) * test_size)\n",
    "    validation_count_0 = int(len(class_0) * validation_size)\n",
    "\n",
    "    class_1 = class_1.sample(frac=1)\n",
    "    class_0 = class_0.sample(frac=1)\n",
    "\n",
    "    # Split each class into test, validation, and train sets\n",
    "    test_data = pd.concat([class_1.iloc[:test_count_1], class_0.iloc[:test_count_0]])\n",
    "    validation_data = pd.concat([\n",
    "        class_1.iloc[test_count_1:test_count_1 + validation_count_1],\n",
    "        class_0.iloc[test_count_0:test_count_0 + validation_count_0]\n",
    "    ])\n",
    "    train_data = pd.concat([\n",
    "        class_1.iloc[test_count_1 + validation_count_1:],\n",
    "        class_0.iloc[test_count_0 + validation_count_0:]\n",
    "    ])\n",
    "\n",
    "    # Split features and target for each set\n",
    "    X_train = train_data.drop('TARGET',axis=1)\n",
    "    X_test = test_data.drop('TARGET',axis=1)\n",
    "    X_val = validation_data.drop('TARGET',axis=1)\n",
    "    y_train = train_data['TARGET']\n",
    "    y_test = test_data['TARGET']\n",
    "    y_val = validation_data['TARGET']\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 153490    1\n",
       "178483    1\n",
       "41261     1\n",
       "33236     1\n",
       "73006     1\n",
       "         ..\n",
       "123583    0\n",
       "214837    0\n",
       "176260    0\n",
       "60397     0\n",
       "68819     0\n",
       "Name: TARGET, Length: 26341, dtype: int64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = stratified_split(df)\n",
    "y_val.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Split\n",
    "\n",
    "def custom_split(data, valid_prop = 0.1, test_prop = 0.1, random_seed = 1738):\n",
    "\n",
    "    train_prop = 1 - valid_prop - test_prop\n",
    "\n",
    "    # define bins for age and income\n",
    "    age_bins = [0, 40, 60, np.inf]\n",
    "    age_labels = ['young', 'middle_aged', 'senior']\n",
    "    income_bins = [0, 30000, 70000, np.inf]\n",
    "    income_labels = ['low', 'medium', 'high']\n",
    "\n",
    "    # convert age to years\n",
    "    data['age'] = data['DAYS_BIRTH']/-365\n",
    "\n",
    "    # create binned variables\n",
    "    data['age_group'] = pd.cut(data['age'], bins=age_bins, labels=age_labels)\n",
    "    data['income_group'] = pd.cut(data['AMT_INCOME_TOTAL'], bins=income_bins, labels=income_labels)\n",
    "\n",
    "    # create a key for each group (combination of gender, age, and income)\n",
    "    data['group_key'] = data['CODE_GENDER_M'].astype(str) + '_' + data['age_group'].astype(str) + '_' + data['income_group'].astype(str)\n",
    "\n",
    "    # shuffle the data\n",
    "    data = data.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "    # split the data based on key\n",
    "    train_data = pd.DataFrame()\n",
    "    val_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for key, group in data.group_by('group_key'):\n",
    "        n = len(group)\n",
    "        n_train = int(n * train_prop)\n",
    "        n_val = int(n * valid_prop)\n",
    "\n",
    "        train_data = pd.concat([train_data, group[:n_train]])\n",
    "        val_data = pd.concat([val_data, group[n_train:n_train + n_val]])\n",
    "        test_data = pd.concat([test_data, group[n_train + n_val:]])\n",
    "\n",
    "    # drop all unnecesary columns\n",
    "    train_data = train_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "    val_data = val_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "    test_data = test_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "\n",
    "    X_train = train_data.drop(['TARGET'])\n",
    "    y_train = train_data['TARGET']\n",
    "\n",
    "    X_validation = val_data.drop(['TARGET'])\n",
    "    y_validation = val_data['TARGET']\n",
    "\n",
    "    X_test = test_data.drop(['TARGET'])\n",
    "    y_test = test_data['TARGET']\n",
    "\n",
    "    return X_train, y_train, X_validation, y_validation, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_train_test_split(X, y, test_size=0.2, val_size=0.2, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    n = len(X)\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_indices = indices[:int(n * test_size)]\n",
    "    val_indices = indices[int(n * test_size):int(n * (test_size + val_size))]\n",
    "    train_indices = indices[int(n * (test_size + val_size)):]\n",
    "    \n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    X_val, y_val = X[val_indices], y[val_indices]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def compute_accuracy(truth, predicted):\n",
    "    return np.mean(truth == predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "def calculate_f1(y_true, y_pred):\n",
    "    TP = FP = TN = FN = 0\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true == 1 and pred == 1:\n",
    "            TP += 1\n",
    "        elif true == 0 and pred == 1:\n",
    "            FP += 1\n",
    "        elif true == 0 and pred == 0:\n",
    "            TN += 1\n",
    "        elif true == 1 and pred == 0:\n",
    "            FN += 1  ,\n",
    "\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roc_auc(y_true, y_prob):\n",
    "  sorted_indices = np.argsort(y_prob)\n",
    "  true_sort = y_true[sorted_indices]\n",
    "  prob_sort = y_prob[sorted_indices]\n",
    "\n",
    "  TP = np.cumsum(true_sort)\n",
    "  FP = np.cumsum(1 - true_sort)\n",
    "\n",
    "  TPR = TP / TP[-1]\n",
    "  FPR = FP / FP[-1]\n",
    "\n",
    "  # rocauc\n",
    "  rocauc_score = np.trapz(FPR, TPR)\n",
    "\n",
    "  return rocauc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression W/ Penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# logistic regression w penalty\u001b[39;00m\n\u001b[1;32m      2\u001b[0m lr_penalty \u001b[38;5;241m=\u001b[39m LogisticRegression(penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m lr_penalty\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m      4\u001b[0m w \u001b[38;5;241m=\u001b[39m lr_penalty\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m b \u001b[38;5;241m=\u001b[39m lr_penalty\u001b[38;5;241m.\u001b[39mintercept_[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1172\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1172\u001b[0m     solver \u001b[38;5;241m=\u001b[39m _check_solver(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual)\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1175\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_ratio parameter is only used when penalty is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(penalty=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[1;32m   1179\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:67\u001b[0m, in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_solver\u001b[39m(solver, penalty, dual):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m penalty \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m supports only \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or None penalties, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpenalty\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpenalty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         )\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dual:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m supports only dual=False, got dual=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdual\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "# logistic regression w penalty\n",
    "lr_penalty = LogisticRegression(penalty='l1', C=1.0)\n",
    "lr_penalty.fit(X, y)\n",
    "w = lr_penalty.coef_[0]\n",
    "b = lr_penalty.intercept_[0]\n",
    "print(f'intercept: {b} \\n weights: {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Model\n",
    "#SVC\n",
    "svc_model = SVC(gamma='auto', kernel='linear') #Can add standard scaler if you want to scale, but left it out to interpret results\n",
    "svc_model.fit(X, y)\n",
    "weights = svc_model.coef_\n",
    "b = svc_model.intercept_\n",
    "print(f'weights: {weights} \\n constant: {b}')\n",
    "print(f'Actual decision boundary: {-b/weights}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[-6.99163540e-03  1.31726591e-07  2.51570304e-06  7.90656431e-06\n",
      "  -2.97870729e-06  3.30432518e+00  3.10964090e-05  6.09622973e-05\n",
      "   1.22852234e-05  6.92994698e-05 -5.49536286e-14 -1.13795177e+00\n",
      "   2.32766005e-01 -1.04844708e-01 -6.25567688e-02 -3.06116334e-02\n",
      "   1.04697501e-02 -1.36067968e-01  3.02887942e-01  2.76813800e-03\n",
      "  -2.55896995e-01  1.49182311e-01 -1.99011053e-01  3.04084734e-01\n",
      "   3.83162041e-03  3.11606065e-02 -2.58909916e+00  2.51117890e-02\n",
      "   1.66423113e-01 -2.74171808e-02  6.51061324e-02  9.02112208e-05\n",
      "  -1.89972739e-13  5.84966274e-01 -2.68696131e-01  5.20468085e-01\n",
      "   5.29385595e-01  1.62834989e-01  3.62887028e-01  3.65029890e-01\n",
      "  -1.06538072e+00 -1.13021294e-01  2.83997546e-01 -4.60871568e-01\n",
      "  -5.49975143e-01 -5.08995001e-01 -4.66557311e-01 -1.02500534e+00\n",
      "  -4.28563348e-01 -2.19961398e-01  5.62758668e-01  4.62208840e-01\n",
      "  -2.76730968e-02  1.31825353e-01 -1.53816093e-02 -3.96546600e-03\n",
      "  -1.66288010e-02  3.37600839e-02  2.41319189e-01  4.22802912e-01\n",
      "  -2.71682156e-01  3.72548838e-04 -3.27834494e-02 -2.24157469e-01\n",
      "  -5.34511656e-02  3.86173708e-02 -8.46201299e-02  2.10753113e-02\n",
      "   2.96658991e-02 -6.01450587e-02 -4.42241813e-01  5.05865108e-02\n",
      "  -1.18541995e+00 -3.00947038e-01  1.53792523e-01  4.42972954e-01\n",
      "   4.73662056e-01  8.67542799e-01  7.10562373e-01 -1.59479085e-01\n",
      "  -1.20447940e-02 -4.43692451e-02 -1.26470995e-01  1.18785132e-01\n",
      "   2.45754623e-01 -9.06002748e-02  2.47219648e-01  2.18883097e-01\n",
      "  -6.00143086e-02 -7.46093873e-02 -9.40538718e-02 -2.38605352e-02\n",
      "  -1.54403658e-02 -1.25651313e-02 -2.99350689e-01 -4.95165451e-01\n",
      "  -1.81870526e-01 -1.87049672e-01 -1.38665845e-01 -2.81532948e-01\n",
      "   2.72276546e-02 -3.60055594e-01 -3.59344741e-01 -3.96084679e-01\n",
      "  -3.02613478e-01 -3.96225270e-01 -2.18321638e-01  3.10836395e-02\n",
      "  -2.94680970e-01 -2.09649838e-01 -7.58390646e-01 -6.43667102e-01\n",
      "  -4.65268256e-01 -2.99013648e-02 -1.96743672e-01 -4.49693397e-01\n",
      "  -3.37576419e-01 -2.24354119e-01 -8.01347152e-01 -4.83766233e-01\n",
      "  -2.16050887e-01 -3.10661475e-01  1.03839471e-01 -2.64440062e-01\n",
      "  -6.00865880e-01 -1.16239708e-01 -2.48543538e-01 -5.51743043e-01\n",
      "  -1.56037193e-01  3.58076522e-01 -2.67016440e-01  4.01603486e-02\n",
      "  -3.40661402e-01 -2.47436162e-01 -5.42199221e-01 -9.88403825e-02\n",
      "  -3.44238657e-01 -1.94980529e-01 -3.96156827e-01 -4.83060007e-01\n",
      "  -5.67086747e-02 -8.77571154e-01 -5.48768344e-01 -5.94454834e-01\n",
      "  -1.74941374e-01 -6.92572781e-01 -3.38738070e-01  5.51900799e-01\n",
      "  -1.79126238e-01 -2.73529436e-01 -2.33242150e+01]] \n",
      " constant: [-0.96448307]\n"
     ]
    }
   ],
   "source": [
    "# LDA Model\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_model.fit(X,y)\n",
    "\n",
    "weights = lda_model.coef_\n",
    "b = lda_model.intercept_\n",
    "\n",
    "print(f'weights: {weights} \\n constant: {b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "358eb17b656811ff2b66f9224ea3a080cef3d2bd176ed3d725d04f8c6a569ed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
