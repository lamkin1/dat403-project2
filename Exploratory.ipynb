{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
      "       'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
      "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n",
      "       'ORGANIZATION_TYPE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 5</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 6</th>\n",
       "      <th>ORGANIZATION_TYPE_Trade: type 7</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 1</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 2</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 3</th>\n",
       "      <th>ORGANIZATION_TYPE_Transport: type 4</th>\n",
       "      <th>ORGANIZATION_TYPE_University</th>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-16941</td>\n",
       "      <td>-1588</td>\n",
       "      <td>-4970</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0       1             0          202500.0    406597.5      24700.5   \n",
       "1       0             0          270000.0   1293502.5      35698.5   \n",
       "2       0             0           67500.0    135000.0       6750.0   \n",
       "3       0             0          121500.0    513000.0      21865.5   \n",
       "4       0             0           99000.0    490495.5      27517.5   \n",
       "\n",
       "   AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0         351000.0                    0.018801       -9461           -637   \n",
       "1        1129500.0                    0.003541      -16765          -1188   \n",
       "2         135000.0                    0.010032      -19046           -225   \n",
       "3         513000.0                    0.028663      -19932          -3038   \n",
       "4         454500.0                    0.035792      -16941          -1588   \n",
       "\n",
       "   DAYS_REGISTRATION  ...  ORGANIZATION_TYPE_Trade: type 4  \\\n",
       "0              -3648  ...                                0   \n",
       "1              -1186  ...                                0   \n",
       "2              -4260  ...                                0   \n",
       "3              -4311  ...                                0   \n",
       "4              -4970  ...                                0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Trade: type 5  ORGANIZATION_TYPE_Trade: type 6  \\\n",
       "0                                0                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                0   \n",
       "3                                0                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  \\\n",
       "0                                0                                    0   \n",
       "1                                0                                    0   \n",
       "2                                0                                    0   \n",
       "3                                0                                    0   \n",
       "4                                0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
       "0                                    0                             0   \n",
       "1                                    0                             0   \n",
       "2                                    0                             0   \n",
       "3                                    0                             0   \n",
       "4                                    0                             0   \n",
       "\n",
       "   ORGANIZATION_TYPE_XNA  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('application_train_clean.csv')\n",
    "df = df.drop(['Unnamed: 0','SK_ID_CURR'],axis=1)\n",
    "print(df.columns[df.dtypes == object])\n",
    "df = pd.get_dummies(df, columns = df.select_dtypes(include=['object']).columns, drop_first=True, dtype=int)\n",
    "df.to_csv('cleaned_train.csv', index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop('TARGET',axis=1), df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split\n",
    "def stratified_split(data, test_size=0.1, validation_size = 0.1):\n",
    "\n",
    "    class_1 = data[data['TARGET'] == 1]\n",
    "    class_0 = data[data['TARGET'] == 0]\n",
    "\n",
    "    test_count_1 = int(len(class_1) * test_size)\n",
    "    validation_count_1 = int(len(class_1) * validation_size)\n",
    "    test_count_0 = int(len(class_0) * test_size)\n",
    "    validation_count_0 = int(len(class_0) * validation_size)\n",
    "\n",
    "    class_1 = class_1.sample(frac=1)\n",
    "    class_0 = class_0.sample(frac=1)\n",
    "\n",
    "    # Split each class into test, validation, and train sets\n",
    "    test_data = pd.concat([class_1.iloc[:test_count_1], class_0.iloc[:test_count_0]])\n",
    "    validation_data = pd.concat([\n",
    "        class_1.iloc[test_count_1:test_count_1 + validation_count_1],\n",
    "        class_0.iloc[test_count_0:test_count_0 + validation_count_0]\n",
    "    ])\n",
    "    train_data = pd.concat([\n",
    "        class_1.iloc[test_count_1 + validation_count_1:],\n",
    "        class_0.iloc[test_count_0 + validation_count_0:]\n",
    "    ])\n",
    "\n",
    "    # Split features and target for each set\n",
    "    X_train = train_data.drop('TARGET',axis=1)\n",
    "    X_test = test_data.drop('TARGET',axis=1)\n",
    "    X_val = validation_data.drop('TARGET',axis=1)\n",
    "    y_train = train_data['TARGET']\n",
    "    y_test = test_data['TARGET']\n",
    "    y_val = validation_data['TARGET']\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 134495    1\n",
       "78076     1\n",
       "166992    1\n",
       "72513     1\n",
       "158398    1\n",
       "         ..\n",
       "63766     0\n",
       "135108    0\n",
       "167545    0\n",
       "101199    0\n",
       "155797    0\n",
       "Name: TARGET, Length: 26341, dtype: int64>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = stratified_split(df)\n",
    "y_val.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         202500.0\n",
       "1         270000.0\n",
       "2          67500.0\n",
       "3         121500.0\n",
       "4          99000.0\n",
       "            ...   \n",
       "263414    112500.0\n",
       "263415    112500.0\n",
       "263416    153000.0\n",
       "263417    171000.0\n",
       "263418    157500.0\n",
       "Name: AMT_INCOME_TOTAL, Length: 263419, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Split\n",
    "\n",
    "def custom_split(data, valid_prop = 0.1, test_prop = 0.1, random_seed = 1738):\n",
    "\n",
    "    train_prop = 1 - valid_prop - test_prop\n",
    "\n",
    "    # define bins for age and income\n",
    "    age_bins = [0, 40, 60, np.inf]\n",
    "    age_labels = ['young', 'middle_aged', 'senior']\n",
    "    income_bins = [0, 30000, 70000, np.inf]\n",
    "    income_labels = ['low', 'medium', 'high']\n",
    "\n",
    "    # convert age to years\n",
    "    data['age'] = data['DAYS_BIRTH']/-365\n",
    "\n",
    "    # create binned variables\n",
    "    data['age_group'] = pd.cut(data['age'], bins=age_bins, labels=age_labels)\n",
    "    data['income_group'] = pd.cut(data['AMT_INCOME_TOTAL'], bins=income_bins, labels=income_labels)\n",
    "\n",
    "    # create a key for each group (combination of gender, age, and income)\n",
    "    data['group_key'] = data['CODE_GENDER_M'].astype(str) + '_' + data['age_group'].astype(str) + '_' + data['income_group'].astype(str)\n",
    "\n",
    "    # shuffle the data\n",
    "    data = data.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "    # split the data based on key\n",
    "    train_data = pd.DataFrame()\n",
    "    val_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for key, group in data.group_by('group_key'):\n",
    "        n = len(group)\n",
    "        n_train = int(n * train_prop)\n",
    "        n_val = int(n * valid_prop)\n",
    "\n",
    "        train_data = pd.concat([train_data, group[:n_train]])\n",
    "        val_data = pd.concat([val_data, group[n_train:n_train + n_val]])\n",
    "        test_data = pd.concat([test_data, group[n_train + n_val:]])\n",
    "\n",
    "    # drop all unnecesary columns\n",
    "    train_data = train_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "    val_data = val_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "    test_data = test_data.drop(columns=['age','age_group', 'income_group', 'strat_key'])\n",
    "\n",
    "    return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_train_test_split(X, y, test_size=0.2, val_size=0.2, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    n = len(X)\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_indices = indices[:int(n * test_size)]\n",
    "    val_indices = indices[int(n * test_size):int(n * (test_size + val_size))]\n",
    "    train_indices = indices[int(n * (test_size + val_size)):]\n",
    "    \n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    X_val, y_val = X[val_indices], y[val_indices]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         0\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "263414    0\n",
       "263415    0\n",
       "263416    0\n",
       "263417    0\n",
       "263418    0\n",
       "Name: CODE_GENDER_M, Length: 263419, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "def compute_accuracy(truth, predicted):\n",
    "    return np.mean(truth == predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "def calculate_f1(y_true, y_pred):\n",
    "    TP = FP = TN = FN = 0\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true == 1 and pred == 1:\n",
    "            TP += 1\n",
    "        elif true == 0 and pred == 1:\n",
    "            FP += 1\n",
    "        elif true == 0 and pred == 0:\n",
    "            TN += 1\n",
    "        elif true == 1 and pred == 0:\n",
    "            FN += 1  ,\n",
    "\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roc_auc(y_true, y_prob):\n",
    "  sorted_indices = np.argsort(y_prob)\n",
    "  true_sort = y_true[sorted_indices]\n",
    "  prob_sort = y_prob[sorted_indices]\n",
    "\n",
    "  TP = np.cumsum(true_sort)\n",
    "  FP = np.cumsum(1 - true_sort)\n",
    "\n",
    "  TPR = TP / TP[-1]\n",
    "  FPR = FP / FP[-1]\n",
    "\n",
    "  # rocauc\n",
    "  rocauc_score = np.trapz(FPR, TPR)\n",
    "\n",
    "  return rocauc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[2024-11-12T22:16:19.393Z] From https://github.com/lamkin1/data403-project2\n",
    " * branch            main       -> FETCH_HEAD\n",
    "hint: You have divergent branches and need to specify how to reconcile them.\n",
    "hint: You can do so by running one of the following commands sometime before\n",
    "hint: your next pull:\n",
    "hint: \n",
    "hint:   git config pull.rebase false  # merge\n",
    "hint:   git config pull.rebase true   # rebase\n",
    "hint:   git config pull.ff only       # fast-forward only\n",
    "hint: \n",
    "hint: You can replace \"git config\" with \"git config --global\" to set a default\n",
    "hint: preference for all repositories. You can also pass --rebase, --no-rebase,\n",
    "hint: or --ff-only on the command line to override the configured default per\n",
    "hint: invocation.\n",
    "fatal: Need to specify how to reconcile divergent branches.\n",
    "[2024-11-12T22:16:20.481Z] > git status -z -uall [25ms]\n",
    "[2024-11-12T22:16:20.504Z] > git symbolic-ref --short HEAD [22ms]\n",
    "[2024-11-12T22:16:20.530Z] > git for-each-ref --format=%(refname)%00%(upstream:short)%00%(objectname)%00%(upstream:track)%00%(upstream:remotename)%00%(upstream:remoteref) refs/heads/main refs/remotes/main [25ms]\n",
    "[2024-11-12T22:16:20.557Z] > git remote --verbose [25ms]\n",
    "[2024-11-12T22:16:20.565Z] > git for-each-ref --sort -committerdate --format %(refname) %(objectname) %(*objectname) [34ms]\n",
    "[2024-11-12T22:16:20.606Z] > git config --get commit.template [35ms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression W/ Penalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression w penalty\n",
    "lr_penalty = LogisticRegression(penalty='l1', C=1.0)\n",
    "lr_penalty.fit(X, y)\n",
    "w = lr_penalty.coef_[0]\n",
    "b = lr_penalty.intercept_[0]\n",
    "print(f'intercept: {b} \\n weights: {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Model\n",
    "#SVC\n",
    "svc_model = SVC(gamma='auto', kernel='linear') #Can add standard scaler if you want to scale, but left it out to interpret results\n",
    "svc_model.fit(X, y)\n",
    "weights = svc_model.coef_\n",
    "b = svc_model.intercept_\n",
    "print(f'weights: {weights} \\n constant: {b}')\n",
    "print(f'Actual decision boundary: {-b/weights}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "358eb17b656811ff2b66f9224ea3a080cef3d2bd176ed3d725d04f8c6a569ed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
